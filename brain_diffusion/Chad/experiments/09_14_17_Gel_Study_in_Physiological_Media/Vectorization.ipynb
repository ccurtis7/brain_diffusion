{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('C:\\\\Users\\\\koolk\\\\Desktop\\\\brain-diffusion\\\\Chad_functions_and_unittests'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stat\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import numpy.linalg as la\n",
    "\n",
    "pi = np.pi\n",
    "sin = np.sin\n",
    "cos = np.cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from MSD_utils import get_data_pups, build_time_array, return_average, avg_all, graph_single_variable\n",
    "from MSD_utils import SD_all, return_SD, range_and_ticks, choose_y_axis_params, data_prep_for_plotting_pups\n",
    "from MSD_utils import fill_in_and_split, plot_traj_length_histogram, plot_traj, filter_out_short_traj\n",
    "from MSD_utils import plot_trajectory_overlay, quality_control\n",
    "\n",
    "from MSD_utils import diffusion_coefficient_point_derivative, diffusion_coefficient_linear_regression\n",
    "from MSD_utils import calculate_diffusion_coefficients, diffusion_bar_chart, summary_barcharts\n",
    "from MSD_utils import calculate_MMSDs, plot_general_histogram, plot_MSD_histogram, plot_all_MSD_histograms\n",
    "from MSD_utils import fillin2, MSD_iteration, vectorized_MMSD_calcs\n",
    "from MSD_utils import get_data_gels, data_prep_for_plotting_gels, plot_all_MSD_histograms_gels, quality_control_gels\n",
    "from MSD_utils import calculate_diffusion_coefficients_gels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"./{region}/{surface_functionality}/{slic}/\"\n",
    "path = \"./{region}/{surface_functionality}/{slic}/geoM2xy_{sample_name}.csv\"\n",
    "frames = 480\n",
    "SD_frames = [1, 10, 19, 28]\n",
    "conversion = (0.16, 9.91, 1)#(0.3, 3.95, 1)\n",
    "to_frame = 60\n",
    "dimension = \"2D\"\n",
    "time_to_calculate = 1\n",
    "\n",
    "base = \"in_agarose\"\n",
    "base_name = \"RED\"\n",
    "test_bins = np.linspace(0, 75, 76)\n",
    "\n",
    "# name = 'RED_KO_PEG_P1_S1_cortex'\n",
    "cut = 1\n",
    "totvids = 15\n",
    "frame_m = 480  # atm I can't go lower than the actual value.\n",
    "conversion = (0.16, 9.91, 1)\n",
    "\n",
    "parameters = {}\n",
    "parameters[\"channels\"] = [\"RED\"]\n",
    "#parameters[\"genotypes\"] = [\"WT\"]\n",
    "#parameters[\"pups\"] = [\"P1\", \"P2\", \"P3\"]\n",
    "parameters[\"surface functionalities\"] = [\"PEG\", \"nPEG\"]\n",
    "parameters[\"slices\"] = [\"S1\", \"S2\", \"S3\", \"S4\"]\n",
    "parameters[\"regions\"] = [\"withCa\", \"noCa\"]\n",
    "parameters[\"replicates\"] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "parameters[\"slice suffixes\"] = ['a', 'b', 'c', 'd']\n",
    "\n",
    "\n",
    "channels = parameters[\"channels\"]\n",
    "#genotypes = parameters[\"genotypes\"]\n",
    "#pups = parameters[\"pups\"]\n",
    "surface_functionalities = parameters[\"surface functionalities\"]\n",
    "slices = parameters[\"slices\"]\n",
    "regions = parameters[\"regions\"]\n",
    "replicates = parameters[\"replicates\"]\n",
    "suffixes = parameters[\"slice suffixes\"]\n",
    "\n",
    "y_range, ticks_y, dec_y, x_range, ticks_x, dec_x = 8, 2, 1, 3, 1, 1\n",
    "frames = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geoM1x = {}\n",
    "geoM1y = {}\n",
    "geoM2xy = {}\n",
    "SM1x = {}\n",
    "SM1y = {}\n",
    "SM2xy = {}\n",
    "\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        for region in regions:\n",
    "            slice_counter = 0\n",
    "            for slic in slices:\n",
    "                suffix = suffixes[slice_counter]\n",
    "                sample_name = \"{}_{}_{}_{}_{}\".format(channel, surface_functionality, base, region, slic)\n",
    "                DIR = folder.format(region = region, surface_functionality = surface_functionality, slic = slic)\n",
    "                \n",
    "                total1, xs, ys, x, y = MSD_iteration(DIR, sample_name, cut, totvids, conversion, frame_m)\n",
    "\n",
    "                geoM1x[sample_name], geoM1y[sample_name], geoM2xy[sample_name], SM1x[sample_name], SM1y[sample_name],\\\n",
    "                    SM2xy[sample_name] = vectorized_MMSD_calcs(frames, total1, xs, ys, x, y, frame_m)\n",
    "                np.savetxt(DIR+'geoM2xy_{}.csv'.format(sample_name), geoM2xy[sample_name], delimiter=',')\n",
    "                np.savetxt(DIR+'SM2xy_{}.csv'.format(sample_name), SM2xy[sample_name], delimiter=',')\n",
    "                \n",
    "#                 geoM2xy[sample_name] = np.genfromtxt(DIR + 'geoM2xy_{}.csv'.format(sample_name), delimiter=\",\");\n",
    "#                 SM2xy[sample_name] = np.genfromtxt(DIR + \"SM2xy_{}.csv\".format(sample_name), delimiter=\",\");\n",
    "                \n",
    "                slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "units = len(geoM2xy)\n",
    "duplicates = []\n",
    "\n",
    "counter = 0\n",
    "for keys in geoM2xy:\n",
    "    duplicates.append(keys.split('_S')[0]);\n",
    "    counter = counter + 1\n",
    "    \n",
    "seen = set()\n",
    "uniq = []\n",
    "for x in duplicates:\n",
    "    if x not in seen:\n",
    "        uniq.append(x)\n",
    "        seen.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_avg = np.zeros((len(slices), frames))\n",
    "averaged = {}\n",
    "stded = {}\n",
    "upper = {}\n",
    "lower = {}\n",
    "\n",
    "for x in uniq:\n",
    "    counter = 0\n",
    "    for slic in slices:\n",
    "        sample_name = \"{}_{}\".format(x, slic);\n",
    "        to_avg[counter, :] = geoM2xy[sample_name]\n",
    "        counter = counter + 1;\n",
    "    averaged[x] = np.mean(to_avg, axis=0)\n",
    "    stded[x] = np.std(to_avg, axis=0)/2\n",
    "    upper[x] = averaged[x] + stded[x]\n",
    "    lower[x] = averaged[x] - stded[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time, time_SD = build_time_array(frames, conversion, SD_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (16, 8))\n",
    "filename = 'diffusion_varying_calcium.png'\n",
    "x_range = 5;\n",
    "y_range = 8;\n",
    "\n",
    "tick_size = 28;\n",
    "label_size = 40;\n",
    "legend_size = 20;\n",
    "width = 4\n",
    "\n",
    "time = time[0:480];\n",
    "cgamut = ['skyblue', 'limegreen', 'salmon', 'violet'];\n",
    "lgamut = ['blue', 'green', 'red', 'purple'];\n",
    "\n",
    "counter = 0;\n",
    "for x in uniq:\n",
    "    test = x;\n",
    "    ax1.fill_between(time[1:], lower[test][1:], averaged[test][1:], color=cgamut[counter], alpha = 0.5);\n",
    "    ax1.fill_between(time[1:], averaged[test][1:], upper[test][1:], color=cgamut[counter], alpha = 0.5);\n",
    "    ax1.plot(time[1:], averaged[test][1:], color = lgamut[counter], label = test, linewidth = width)\n",
    "    counter = counter + 1;\n",
    "\n",
    "plt.gca().set_xlim([0, x_range])\n",
    "plt.gca().set_ylim([0, y_range])\n",
    "ax1.legend(loc='best', prop={'size': legend_size})\n",
    "\n",
    "ax1.title.set_fontsize(tick_size)\n",
    "ax1.set_xlabel('Time (s)', fontsize=label_size)\n",
    "ax1.set_ylabel(r'MSD ($\\mu$m$^2$)', fontsize=label_size)\n",
    "ax1.tick_params(direction='out', pad=16)\n",
    "\n",
    "for item in ([ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(tick_size)\n",
    "    \n",
    "plt.savefig('{}'.format(filename), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(0.0, 2, 0.01)\n",
    "y1 = np.sin(2*np.pi*x)\n",
    "y2 = 1.2*np.sin(4*np.pi*x)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, sharex=True)\n",
    "\n",
    "ax1.fill_between(x, 0, y1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "averaged[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for keys in avg_sets:\n",
    "    all_avg[avg_sets[keys]] = return_average(data, frames, avg_sets[keys])\n",
    "return all_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, avg_over_slices, time, time_SD, average_over_slices, all_SD_over_slices = \\\n",
    "    data_prep_for_plotting_gels(path, frames, SD_frames, conversion, to_frame, parameters, base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all_MSD_histograms_gels(parameters, folder, SM2xy, time, test_bins, 1, set_y_limit=True, y_range=5000, set_x_limit=True, x_range=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"./{functionality}/{slic}/\"\n",
    "path = \"./{functionality}/{slic}/geoM2xy_{sample_name}.csv\"\n",
    "path2 = \"./{functionality}/{slic}/Traj_{sample_name}.tif.csv\"\n",
    "\n",
    "frames = 120\n",
    "SD_frames2 = [1, 2, 3, 4]\n",
    "conversion = (1.24, 1.93, 1)#(0.3, 3.95, 1)\n",
    "to_frame = 60\n",
    "dimension = \"2D\"\n",
    "time_to_calculate = 1\n",
    "\n",
    "base = \"0-4p_agarose\"\n",
    "base_name = \"RED\"\n",
    "test_bins = np.linspace(0, 75, 76)\n",
    "\n",
    "# name = 'RED_KO_PEG_P1_S1_cortex'\n",
    "cut = 4\n",
    "totvids = 10\n",
    "frame_m = 120  # atm I can't go lower than the actual value.\n",
    "\n",
    "parameters = {}\n",
    "parameters[\"channels\"] = [\"RED\"]\n",
    "parameters[\"surface functionalities\"] = [\"nPEG\"]\n",
    "parameters[\"slices\"] = [\"1\", \"2\", \"3\", \"4\"]\n",
    "parameters[\"replicates\"] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "parameters[\"slice suffixes\"] = ['a', 'b', 'c', 'd']\n",
    "\n",
    "\n",
    "channels = parameters[\"channels\"]\n",
    "surface_functionalities = parameters[\"surface functionalities\"]\n",
    "slices = parameters[\"slices\"]\n",
    "replicates = parameters[\"replicates\"]\n",
    "suffixes = parameters[\"slice suffixes\"]\n",
    "\n",
    "frames2 = 120\n",
    "interv = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geoM1x = {}\n",
    "geoM1y = {}\n",
    "geoM2xy = {}\n",
    "SM1x = {}\n",
    "SM1y = {}\n",
    "SM2xy = {}\n",
    "\n",
    "for channel in channels:\n",
    "    for surface_functionality in surface_functionalities:\n",
    "        slice_counter = 0\n",
    "        for slic in slices:\n",
    "            suffix = suffixes[slice_counter]\n",
    "            sample_name = \"{}_{}_0-4p_agarose_{}\".format(channel, surface_functionality, slic)\n",
    "            DIR = folder.format(functionality = surface_functionality, slic = slic)\n",
    "            frames, total1, xs, ys, x, y = MSD_iteration(DIR, sample_name, cut, totvids, conversion, frame_m, suffix)\n",
    "\n",
    "            geoM1x[sample_name], geoM1y[sample_name], geoM2xy[sample_name], SM1x[sample_name], SM1y[sample_name],\\\n",
    "                SM2xy[sample_name] = vectorized_MMSD_calcs(frames, total1, xs, ys, x, y, frame_m)\n",
    "            np.savetxt(DIR+'geoM2xy_{}.csv'.format(sample_name), geoM2xy[sample_name], delimiter=',')\n",
    "            np.savetxt(DIR+'SM2xy_{}.csv'.format(sample_name)), SM2xy[sample_name], delimiter=',')\n",
    "\n",
    "            slice_counter = slice_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2, avg_over_slices2, time2, time_SD2, average_over_slices2, all_SD_over_slices2 = \\\n",
    "    data_prep_for_plotting_gels(path, frames2, SD_frames2, conversion, to_frame, parameters, base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all_MSD_histograms_gels(parameters, base, folder, SM2xy, time2, test_bins, 1, set_y_limit=True, y_range=5000, set_x_limit=True, x_range=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_control_gels(path2, folder, frames, conversion, parameters, base, interv, cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quality_control_gels(path2, folder, frames, conversion, parameters, base, interv, cut):\n",
    "    \"\"\"\n",
    "    This function plots a histogram of trajectory lengths (in units of frames) and two types of plots of\n",
    "    trajectories (original and overlay).\n",
    "\n",
    "    Inputs:\n",
    "    path2: string.  Name of input trajectory csv files.\n",
    "    folder: string. Name of folder to which to save results.\n",
    "    frames: integer.  Total number of frames in videos.\n",
    "    conversion: array.  Contains microns per pixel and frames per second of videos.\n",
    "    parameters:\n",
    "\n",
    "    parameters = {}\n",
    "    parameters[\"channels\"] = [\"RED\"]\n",
    "    parameters[\"surface functionalities\"] = [\"PEG\"]\n",
    "    parameters[\"slices\"] = [\"S1\", \"S2\", \"S3\"]\n",
    "    parameters[\"replicates\"] = [1, 2, 3, 4]\n",
    "\n",
    "    cut: integer.  Minimum number of frames a trajectory must have in order to be plotted.\n",
    "    \"\"\"\n",
    "\n",
    "    channels = parameters[\"channels\"]\n",
    "    surface_functionalities = parameters[\"surface functionalities\"]\n",
    "    slices = parameters[\"slices\"]\n",
    "    replicates = parameters[\"replicates\"]\n",
    "    SD_frames = [1, 7, 14, 15]\n",
    "\n",
    "    trajectory = {}\n",
    "    names_with_replicates = {}\n",
    "    data = {}\n",
    "\n",
    "    particles_unfiltered = {}\n",
    "    framed_unfiltered = {}\n",
    "    x_data_unfiltered = {}\n",
    "    y_data_unfiltered = {}\n",
    "    total_unfiltered = {}\n",
    "    particles = {}\n",
    "    framed = {}\n",
    "    x_data = {}\n",
    "    y_data = {}\n",
    "    total = {}\n",
    "    tlength = {}\n",
    "    x_microns = {}\n",
    "    y_microns = {}\n",
    "    x_particle = {}\n",
    "    y_particle = {}\n",
    "\n",
    "    x_original_frames = {}\n",
    "    y_original_frames = {}\n",
    "\n",
    "    x_adjusted_frames = {}\n",
    "    y_adjusted_frames = {}\n",
    "\n",
    "    counter2 = 0\n",
    "\n",
    "    for channel in channels:\n",
    "            for surface_functionality in surface_functionalities:\n",
    "                        for slic in slices:\n",
    "                            for replicate in replicates:\n",
    "                                # Establishing sample names and extracting data from csv files.\n",
    "                                counter2 = counter2 + 1\n",
    "                                sample_name_long = \"{}_{}_{}_{}_{}\".format(channel, surface_functionality, base, slic, replicate)\n",
    "                                names_with_replicates[counter2] = sample_name_long\n",
    "\n",
    "                                filename = path2.format(functionality = surface_functionality, slic = slic, sample_name=sample_name_long)\n",
    "                                data[sample_name_long] = np.genfromtxt(filename, delimiter=\",\")\n",
    "                                data[sample_name_long] = np.delete(data[sample_name_long], 0, 1)\n",
    "\n",
    "                                # Names of output plots\n",
    "                                fold = folder.format(functionality = surface_functionality, slic = slic)\n",
    "                                \n",
    "                                logplot = fold +'{}_logplot'.format(sample_name_long)\n",
    "                                Mplot = fold +'{}_Mplot'.format(sample_name_long)\n",
    "                                Dplot = fold +'{}_Dplot'.format(sample_name_long)\n",
    "                                Hplot = fold +'{}_Hplot'.format(sample_name_long)\n",
    "                                Hlogplot = fold +'{}_Hlogplot'.format(sample_name_long)\n",
    "                                Cplot = fold +'{}_Cplot'.format(sample_name_long)\n",
    "                                Tplot = fold +'{}_Tplot'.format(sample_name_long)\n",
    "                                T2plot = fold +'{}_T2plot'.format(sample_name_long)\n",
    "                                lenplot = fold +'{}_lenplot'.format(sample_name_long)\n",
    "\n",
    "                                # Fill in data and split into individual trajectories\n",
    "                                particles_unfiltered[counter2], framed_unfiltered[counter2], x_data_unfiltered[counter2],\\\n",
    "                                    y_data_unfiltered[counter2] = fill_in_and_split(data[names_with_replicates[counter2]])\n",
    "\n",
    "                                total_unfiltered[counter2] = int(max(particles_unfiltered[counter2]))\n",
    "\n",
    "                                # Filter out short trajectories\n",
    "                                particles[counter2], framed[counter2], x_data[counter2], y_data[counter2] =\\\n",
    "                                    filter_out_short_traj(particles_unfiltered[counter2], framed_unfiltered[counter2],\n",
    "                                                          x_data_unfiltered[counter2], y_data_unfiltered[counter2], cut)\n",
    "\n",
    "                                # Convert to microns and seconds\n",
    "                                time, time_SD = build_time_array(frames, conversion, SD_frames)\n",
    "                                framen = np.linspace(0, frames, frames+1).astype(np.int64)\n",
    "                                total[counter2] = int(max(particles[counter2]))\n",
    "                                tlength[counter2] = np.zeros(total[counter2])\n",
    "\n",
    "                                x_microns[counter2] = x_data[counter2]*conversion[0]\n",
    "                                y_microns[counter2] = y_data[counter2]*conversion[0]\n",
    "\n",
    "                                # Adjust frames (probably unneccesary, but I did it...)\n",
    "                                x_particle[counter2] = {}\n",
    "                                y_particle[counter2] = {}\n",
    "\n",
    "                                x_original_frames[counter2] = {}\n",
    "                                y_original_frames[counter2] = {}\n",
    "\n",
    "                                x_adjusted_frames[counter2] = {}\n",
    "                                y_adjusted_frames[counter2] = {}\n",
    "\n",
    "                                for num in range(1, total[counter2] + 1):\n",
    "                                    hold = np.where(particles[counter2] == num)\n",
    "                                    itindex = hold[0]\n",
    "                                    min1 = min(itindex)\n",
    "                                    max1 = max(itindex)\n",
    "                                    x_particle[counter2][num] = x_microns[counter2][min1:max1+1]\n",
    "                                    y_particle[counter2][num] = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_original_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    y_original_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    x_adjusted_frames[counter2][num] = np.zeros(frames + 1)\n",
    "                                    y_adjusted_frames[counter2][num] = np.zeros(frames + 1)\n",
    "\n",
    "                                    x_original_frames[counter2][num][framed[counter2][min1]:framed[counter2][max1]+1]\\\n",
    "                                        = x_microns[counter2][min1:max1+1]\n",
    "                                    y_original_frames[counter2][num][framed[counter2][min1]:framed[counter2][max1]+1]\\\n",
    "                                        = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_adjusted_frames[counter2][num][0:max1+1-min1] = x_microns[counter2][min1:max1+1]\n",
    "                                    y_adjusted_frames[counter2][num][0:max1+1-min1] = y_microns[counter2][min1:max1+1]\n",
    "\n",
    "                                    x_original_frames[counter2][num] = ma.masked_equal(x_original_frames[counter2][num], 0)\n",
    "                                    y_original_frames[counter2][num] = ma.masked_equal(y_original_frames[counter2][num], 0)\n",
    "                                    x_adjusted_frames[counter2][num] = ma.masked_equal(x_adjusted_frames[counter2][num], 0)\n",
    "                                    y_adjusted_frames[counter2][num] = ma.masked_equal(y_adjusted_frames[counter2][num], 0)\n",
    "\n",
    "                                    tlength[counter2][num - 1] = ma.count(x_adjusted_frames[counter2][num])\n",
    "\n",
    "                                plot_traj(x_original_frames[counter2], y_original_frames[counter2], total[counter2], interv, T2plot)\n",
    "                                plt.gcf().clear()\n",
    "                                plot_trajectory_overlay(x_original_frames[counter2], y_original_frames[counter2], 6, 2, 6, Tplot)\n",
    "                                plt.gcf().clear()\n",
    "                                plot_traj_length_histogram(tlength[counter2], max(tlength[counter2]), lenplot)\n",
    "                                plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Datasets Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because my PEG and nPEG datasets had different framerates, I had to analyze the datasets separately.  My code requires all datasets to have the same framerate, and thus they can't be plotted together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates figure\n",
    "\n",
    "line_colors=['g', 'r', 'b', 'c', 'm', 'k']\n",
    "line_kind='-'\n",
    "labels = ['PEG', 'nPEG']\n",
    "label_size=95\n",
    "legend_size=40 \n",
    "tick_size=50\n",
    "line_width=10\n",
    "fig_size=(20, 18)\n",
    "filename = 'test.png'\n",
    "\n",
    "to_graph = {}\n",
    "counter = 0\n",
    "for keys in average_over_slices:\n",
    "    to_graph[counter] = keys\n",
    "    counter = counter + 1\n",
    "for keys in average_over_slices2:\n",
    "    to_graph[counter] = keys\n",
    "    counter = counter + 1\n",
    "\n",
    "fig = plt.figure(figsize=fig_size, dpi=80)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "line_type = [s + line_kind for s in line_colors]\n",
    "ax.plot(time[0:to_frame], average_over_slices[to_graph[0]][0:to_frame], line_type[0], linewidth=line_width, label=labels[0])\n",
    "ax.errorbar(time_SD, average_over_slices[to_graph[0]][SD_frames], all_SD_over_slices[to_graph[0]], fmt='', linestyle='',\n",
    "            capsize=7, capthick=2, elinewidth=2, color=line_colors[0])\n",
    "\n",
    "ax.plot(time2[0:to_frame], average_over_slices2[to_graph[1]][0:to_frame], line_type[1], linewidth=line_width, label=labels[1])\n",
    "ax.errorbar(time_SD2, average_over_slices2[to_graph[1]][SD_frames2], all_SD_over_slices2[to_graph[1]], fmt='', linestyle='',\n",
    "            capsize=7, capthick=2, elinewidth=2, color=line_colors[1])\n",
    "\n",
    "# A few adjustments to prettify the graph\n",
    "for item in ([ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(tick_size)\n",
    "\n",
    "xmajor_ticks = np.arange(0, x_range+0.0001, ticks_x)\n",
    "ymajor_ticks = np.arange(0, y_range+0.0001, ticks_y)\n",
    "\n",
    "ax.set_xticks(xmajor_ticks)\n",
    "plt.xticks(rotation=-30)\n",
    "ax.set_yticks(ymajor_ticks)\n",
    "ax.title.set_fontsize(tick_size)\n",
    "ax.set_xlabel('Time (s)', fontsize=label_size)\n",
    "ax.set_ylabel(r'MSD ($\\mu$m$^2$)', fontsize=label_size)\n",
    "ax.tick_params(direction='out', pad=16)\n",
    "ax.legend(loc=(0.02, 0.75), prop={'size': legend_size})\n",
    "plt.gca().xaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.{}f'.format(dec_x)))\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FormatStrFormatter('%.{}f'.format(dec_y)))\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.gca().set_xlim([0, x_range+0.0001])\n",
    "plt.gca().set_ylim([0, y_range+0.0001])\n",
    "\n",
    "# Save your figure\n",
    "plt.savefig('{}'.format(filename), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_diffusion_coefficients_gels(channels, surface_functionalities, slices, path, time, time_to_calculate, to_frame, dimension):\n",
    "\n",
    "    \"\"\"\n",
    "    Loads data from csv files and outputs a dictionary following a specified\n",
    "        sample naming convection determined by the input\n",
    "\n",
    "    Parameters:\n",
    "    channels, surface functionalities, media, and concentrations, and replicates\n",
    "        can take ranges or lists.\n",
    "    path is string with substition placeholders for concentration and sample\n",
    "        name (built from channels, surface_functionalities, media,\n",
    "        concentrations, and replicates).\n",
    "\n",
    "    Example:\n",
    "    path = \"./{genotype}/{pup}/{region}/{channel}/geoM2xy_{sample_name}.csv\";\n",
    "    get_data([\"RED\", \"YG\"], [\"WT\", \"KO\", \"HET\"], [\"P1\", \"P2\", \"P3\", \"P4\"],\n",
    "    [\"PEG\", \"noPEG\"], [\"S1\", \"S2\", \"S3\", \"S4\"], [\"cortex\", \"hipp\", \"mid\"],\n",
    "    [1, 2, 3, 4, 5], path)\n",
    "    \"\"\"\n",
    "\n",
    "    data = {}\n",
    "    avg_over_slices_raw = {}\n",
    "    avg_over_pups_raw = {}\n",
    "    names_with_replicates = {}\n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "\n",
    "    diffusion_coef_point_derivative = {}\n",
    "    diffusion_coef_linear_fit = {}\n",
    "\n",
    "    for channel in channels:\n",
    "        for surface_functionality in surface_functionalities:\n",
    "            for slic in slices:\n",
    "                test_value = \"{}_{}_0-4p_agarose_{}\".format(channel, surface_functionality, slic)\n",
    "                avg_over_slices_raw[counter] = test_value\n",
    "                counter = counter + 1\n",
    "                sample_name = test_value\n",
    "                for replicate in replicates:\n",
    "                    sample_name_long = test_value + \"_{}\".format(replicate)\n",
    "                    names_with_replicates[counter2] = sample_name_long\n",
    "                    counter2 = counter2 + 1\n",
    "                filename = path.format(functionality = surface_functionality, slic = slic, sample_name=sample_name)\n",
    "                data[sample_name] = np.genfromtxt(filename, delimiter=\",\")\n",
    "\n",
    "                diffusion_coef_point_derivative[sample_name] =\\\n",
    "                    diffusion_coefficient_point_derivative(data[sample_name], time, time_to_calculate, dimension)\n",
    "                diffusion_coef_linear_fit[sample_name] =\\\n",
    "                    diffusion_coefficient_linear_regression(data[sample_name], time, to_frame, dimension)\n",
    "\n",
    "    return diffusion_coef_point_derivative, diffusion_coef_linear_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_diffusion_coefficients_gels(channels, surface_functionalities, slices, path, time, time_to_calculate, to_frame, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
